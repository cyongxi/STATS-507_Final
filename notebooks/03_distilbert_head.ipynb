{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_uYgDbNNVes"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers datasets evaluate accelerate\n",
        "\n",
        "import os, time, json\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ[\"WANDB_MODE\"] = \"offline\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    DataCollatorWithPadding,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")\n",
        "import evaluate\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "os.makedirs(\"results\", exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Load dataset"
      ],
      "metadata": {
        "id": "CERwkJyFNcs4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_dataset(\"ag_news\")\n",
        "\n",
        "# train\n",
        "split   = ds[\"train\"].train_test_split(\n",
        "    test_size=0.1,\n",
        "    seed=42,\n",
        "    stratify_by_column=\"label\"\n",
        ")\n",
        "train_ds = split[\"train\"]\n",
        "val_ds   = split[\"test\"]\n",
        "test_ds  = ds[\"test\"]\n",
        "\n",
        "print(train_ds)\n",
        "print(val_ds)"
      ],
      "metadata": {
        "id": "9nHkVni6Nnhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##"
      ],
      "metadata": {
        "id": "fWkZdw5XnoQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_df = pd.DataFrame({\"text\": train_ds[\"text\"], \"label\": train_ds[\"label\"]})\n",
        "_sub = _df.groupby(\"label\", group_keys=False).apply(\n",
        "    lambda g: g.sample(n=5000, random_state=42)\n",
        ")\n",
        "train_small = Dataset.from_pandas(_sub.reset_index(drop=True), preserve_index=False)\n",
        "\n",
        "print(train_small)"
      ],
      "metadata": {
        "id": "JyxAwnhbNtFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. DistilBERT v1（max_length=128, 200 steps）"
      ],
      "metadata": {
        "id": "kjZnHhAdnqMB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"distilbert-base-uncased\"\n",
        "tok = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "\n",
        "def preprocess(batch):\n",
        "    return tok(batch[\"text\"], truncation=True, padding=False, max_length=128)\n",
        "\n",
        "enc_train = (\n",
        "    train_small\n",
        "    .map(preprocess, batched=True)\n",
        "    .rename_column(\"label\", \"labels\")\n",
        "    .with_format(\"torch\")\n",
        ")\n",
        "\n",
        "enc_val = (\n",
        "    val_ds\n",
        "    .map(preprocess, batched=True)\n",
        "    .rename_column(\"label\", \"labels\")\n",
        "    .with_format(\"torch\")\n",
        ")\n",
        "\n",
        "collator = DataCollatorWithPadding(tok)\n",
        "\n",
        "enc_train, enc_val"
      ],
      "metadata": {
        "id": "5g9fw2uVNwZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DistilBERT classfication model\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=4\n",
        ")\n",
        "\n",
        "for p in model.base_model.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "all_params       = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Trainable params: {trainable_params:,} / {all_params:,}\")\n"
      ],
      "metadata": {
        "id": "BfXb5-WPN7AK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy + Macro-F1\n",
        "acc_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric  = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    return {\n",
        "        \"accuracy\": acc_metric.compute(predictions=preds, references=labels)[\"accuracy\"],\n",
        "        \"macro_f1\": f1_metric.compute(predictions=preds, references=labels, average=\"macro\")[\"f1\"],\n",
        "    }"
      ],
      "metadata": {
        "id": "0YlGDZEMN_hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"out_distilbert_head\",\n",
        "    max_steps=200,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    do_eval=False,\n",
        "    logging_steps=50,\n",
        "    save_steps=10_000_000,\n",
        "    seed=42,\n",
        "    )"
      ],
      "metadata": {
        "id": "IjvHH2QROHYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=enc_train,\n",
        "    eval_dataset=enc_val,\n",
        "    data_collator=collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=None,\n",
        ")\n",
        "\n",
        "t0 = time.time()\n",
        "trainer.train()\n",
        "train_time_min = (time.time() - t0) / 60.0\n",
        "\n",
        "metrics = trainer.evaluate(enc_val)\n",
        "metrics = {k: float(v) for k, v in metrics.items()}\n",
        "metrics[\"train_time_min\"] = train_time_min\n",
        "\n",
        "print(\"\\n=== DistilBERT head-only on validation set ===\")\n",
        "for k, v in metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\" if isinstance(v, float) else f\"{k}: {v}\")"
      ],
      "metadata": {
        "id": "Dkjk1QBjOL9T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"results/distilbert_head_v1.json\",\"w\") as f:\n",
        "    json.dump(metrics,f,indent=2)\n",
        "\n",
        "pred_out = trainer.predict(enc_val)\n",
        "logits = pred_out.predictions\n",
        "y_true = pred_out.label_ids\n",
        "y_pred = logits.argmax(axis=-1)\n",
        "\n",
        "labels4 = [\"World\",\"Sports\",\"Business\",\"Sci/Tech\"]\n",
        "cm = confusion_matrix(y_true, y_pred, labels=[0,1,2,3])\n",
        "\n",
        "disp = ConfusionMatrixDisplay(cm, display_labels=labels4)\n",
        "plt.figure(figsize=(5.2,4.4))\n",
        "disp.plot(cmap=\"Blues\", values_format=\"d\", colorbar=False)\n",
        "plt.title(\"Confusion Matrix — DistilBERT v1 (128, 200 steps)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"results/confmat_distilbert_v1.png\", dpi=300)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ygGajDGTOT7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Subword Length Analysis"
      ],
      "metadata": {
        "id": "KqAvboZspceY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_texts = train_ds[\"text\"][:20000]\n",
        "enc_no_trunc = tok(sample_texts, truncation=False, add_special_tokens=True)\n",
        "sub_lens = np.array([len(ids) for ids in enc_no_trunc[\"input_ids\"]])\n",
        "\n",
        "p50  = float(np.percentile(sub_lens, 50))\n",
        "p95  = float(np.percentile(sub_lens, 95))\n",
        "t128 = float((sub_lens > 128).mean())\n",
        "t256 = float((sub_lens > 256).mean())\n",
        "\n",
        "print({\"p50\": p50, \"p95\": p95, \"trunc@128\": t128, \"trunc@256\": t256})\n",
        "\n",
        "subword_stats = {\n",
        "    \"p50\": p50,\n",
        "    \"p95\": p95,\n",
        "    \"trunc@128\": t128,\n",
        "    \"trunc@256\": t256,\n",
        "}\n",
        "with open(\"results/subword_stats.json\", \"w\") as f:\n",
        "    json.dump(subword_stats, f, indent=2)"
      ],
      "metadata": {
        "id": "Qk1R3A-4OXF0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##DistilBERT v2（max_length=192, 1000 steps）"
      ],
      "metadata": {
        "id": "LV5xXYsnpfaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"distilbert-base-uncased\"\n",
        "tok_192 = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "\n",
        "def preprocess_192(batch):\n",
        "    \"\"\"\n",
        "    v2 ：change max_length of DistilBERT from128to192。\n",
        "    without padding\n",
        "    \"\"\"\n",
        "    return tok_192(\n",
        "        batch[\"text\"],\n",
        "        truncation=True,\n",
        "        padding=False,\n",
        "        max_length=192,\n",
        "    )\n",
        "\n",
        "\n",
        "enc_train_192 = train_small.map(preprocess_192, batched=True)\n",
        "enc_val_192   = val_ds.map(preprocess_192, batched=True)\n",
        "\n",
        "enc_train_192 = enc_train_192.rename_column(\"label\", \"labels\")\n",
        "enc_val_192   = enc_val_192.rename_column(\"label\", \"labels\")\n",
        "enc_train_192.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "enc_val_192.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
        "\n",
        "collator_192 = DataCollatorWithPadding(tokenizer=tok_192)"
      ],
      "metadata": {
        "id": "uXZMCLtgn-cF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_v2 = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=4\n",
        ")\n",
        "\n",
        "for p in model_v2.base_model.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "trainable_params = sum(p.numel() for p in model_v2.parameters() if p.requires_grad)\n",
        "all_params       = sum(p.numel() for p in model_v2.parameters())\n",
        "print(f\"[v2] Trainable params: {trainable_params:,} / {all_params:,}\")"
      ],
      "metadata": {
        "id": "Arf-_hD2q4gb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args_v2 = TrainingArguments(\n",
        "    output_dir=\"out_distilbert_head_v2_max192\",\n",
        "    max_steps=1000,                    # 200 -> 1000\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    do_eval=False,\n",
        "    logging_steps=50,\n",
        "    save_steps=10_000_000,\n",
        "    seed=42,\n",
        ")"
      ],
      "metadata": {
        "id": "8bDZBvFcq60v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Trainer\n",
        "trainer_v2 = Trainer(\n",
        "    model=model_v2,\n",
        "    args=args_v2,\n",
        "    train_dataset=enc_train_192,\n",
        "    eval_dataset=enc_val_192,\n",
        "    data_collator=collator_192,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=None,\n",
        ")\n",
        "\n",
        "t0 = time.time()\n",
        "trainer_v2.train()\n",
        "train_time_min_v2 = (time.time() - t0) / 60.0\n",
        "\n",
        "metrics_v2 = trainer_v2.evaluate(enc_val_192)\n",
        "metrics_v2 = {k: float(v) for k, v in metrics_v2.items()}\n",
        "metrics_v2[\"train_time_min\"] = train_time_min_v2\n",
        "\n",
        "print(\"\\n=== DistilBERT head-only v2 (max_length=192, 1000 steps) on validation set ===\")\n",
        "for k, v in metrics_v2.items():\n",
        "    print(f\"{k}: {v:.4f}\" if isinstance(v, float) else f\"{k}: {v}\")\n",
        "\n",
        "os.makedirs(\"results\", exist_ok=True)\n",
        "with open(\"results/distilbert_head_v2_max192.json\", \"w\") as f:\n",
        "    json.dump(metrics_v2, f, indent=2)"
      ],
      "metadata": {
        "id": "siMJ4gLGrB-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_out_v2 = trainer_v2.predict(enc_val_192)\n",
        "logits_v2 = pred_out_v2.predictions\n",
        "y_true_v2 = pred_out_v2.label_ids\n",
        "y_pred_v2 = logits_v2.argmax(axis=-1)\n",
        "\n",
        "labels4 = [\"World\",\"Sports\",\"Business\",\"Sci/Tech\"]\n",
        "cm_v2 = confusion_matrix(y_true_v2, y_pred_v2, labels=[0,1,2,3])\n",
        "\n",
        "disp_v2 = ConfusionMatrixDisplay(cm_v2, display_labels=labels4)\n",
        "plt.figure(figsize=(5.2, 4.4))\n",
        "disp_v2.plot(cmap=\"Blues\", values_format=\"d\", colorbar=False)\n",
        "plt.title(\"Confusion Matrix - DistilBERT head-only v2 (max_length=192, 1000 steps)\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"results/confmat_distilbert_head_v2_max192.png\", dpi=300)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "x5jPB5DdrCw0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}